# Copyright (c) 2019 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

description: >-
  MidasNet is a model for monocular depth estimation trained by mixing several datasets;
  as described in the following paper: 
  "Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-Shot Cross-Dataset Transfer"
  <https://arxiv.org/pdf/1907.01341>

  The model input is a blob that consists of a single image of "1x3x224x384" in RGB order.

  The model output is an inverse depth map that is defined up to an unknown scale factor.
task_type: monocular_depth
files:
  - name: midasnet.py
    size: 5511
    sha256: 45d1d3cdee085c22c02d3d6d3fcd1a1c436560705284efcd26f029481415ad6e
    source: 
      $type: google_drive
      id: 1RL4XWlfZVZREFibUJYX2UeczYjyEg0q4
  - name: midasnet.pth
    size: 149751722
    sha256: 617d916c0864b95880aed0b6be6d0629ce8b4c0d28361a559f8e5193a9bb554d
    source:
      $type: google_drive
      id: 1htGnZWcdcyEXxnGuNFQOCC4o6uqvIs_7
framework: pytorch
pytorch_to_onnx:
  - --model-name=MidasNet
  - --model-path=$dl_dir
  - --weights=$dl_dir/midasnet.pth
  - --import-module=midasnet
  - --input-shape=1,3,224,384
  - --output-file=$conv_dir/midasnet.onnx
  - --input-names=image
  - --output-names=inverse_depth
model_optimizer_args:
  - --input=image
  - --reverse_input_channels
  - --output=inverse_depth
  - --input_model=$conv_dir/midasnet.onnx
license: https://drive.google.com/open?id=1p_7P7VKSpD1xM8Ex6p0epZ4TdYFPYjss
